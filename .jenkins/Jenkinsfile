pipeline {
  agent('any')
  // options {
    // githubProjectProperty('https://github.com/HadesArchitect/cassandra')
    // timestamps()
  // }
  environment {
    javaVersionDefault = javaVersionDefault()
    javaVersionsSupported = javaVersionsSupported()
    // javaVersionsSupported = "11"
  }
  stages {
    stage('init') {
      steps {
        script { currentBuild.result='SUCCESS' }
        cleanWs()
      }
    }
    stage('jar') {
      steps {
        buildJob(".build/docker/_docker_run.sh bullseye-build.docker build-jars.sh", "")
      }
    }
    stage('Tests') {
      parallel {
        stage('artifacts') {
          steps {
            buildJob(".build/docker/build-artifacts.sh", "apache-cassandra-*.tar.gz,apache-cassandra-*.jar,apache-cassandra-*.pom")
          }
        }
        // stage('lint') {
        //   steps {
        //     buildJob(".build/docker/check-code.sh", "")
        //   }
        // }
        // stage('debian') {
        //   steps {
        //     buildJob(".build/docker/build-debian.sh", "cassandra_*,cassandra-tools_*")
        //   }
        // }
        // stage('redhat') {
        //   steps {
        //     buildJob(".build/docker/build-redhat.sh rpm", "*.rpm")
        //   }
        // }
        // stage('stress-test') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "stress-test", 1)
        //   }
        // }        
        // stage('cqlsh-test') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "cqlsh-test", 1)
        //   }
        // }
        // stage('fqltool-test') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "fqltool-test", 1)
        //   }
        // }
        // stage('test') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "test", 8)
        //   }
        // }
        // stage('test-trie') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "test-trie", 8)
        //   }
        // }
        stage('test-burn') {
          steps {
            testJob(".build/docker/run-tests.sh", "test-burn", 8)
          }
        }
        stage('test-cdc') {
          steps {
            testJob(".build/docker/run-tests.sh", "test-cdc", 8)
          }
        }
        stage('test-compression') {
          steps {
            testJob(".build/docker/run-tests.sh", "test-compression", 8)
          }
        }
        // stage('long-test') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "long-test", 8)
        //   }
        // }
        // stage('test-oa') {
        //   steps {
        //     testJob(".build/docker/run-tests.sh", "test-oa", 8)
        //   }
        // }
      }
    }
    stage('Summary') {
      steps {
        generateUnifiedTestReport()
        // FIXME – post always
        sendNotifications()
      }
    }
  }
}

///////////////////////////
//// scripting support ////
///////////////////////////


/**
 * Return the default JDK defined by build.xml
 **/
def javaVersionDefault() {
  sh (returnStdout: true, script: 'grep \'property\\s*name=\"java.default\"\' build.xml | sed -ne \'s/.*value=\"\\([^\"]*\\)\".*/\\1/p\'').trim()
}

/**
 * Return the supported JDKs defined by build.xml
 **/
def javaVersionsSupported() {
  sh (returnStdout: true, script: 'grep \'property\\s*name=\"java.supported\"\' build.xml | sed -ne \'s/.*value=\"\\([^\"]*\\)\".*/\\1/p\'').trim()
}

/**
 * Is this a post-commit build (or a pre-commit build)
 **/
def isPostCommit() {
  // any build of a branch found on github.com/apache/cassandra is considered a post-commit (post-merge) CI run
  return "${GIT_URL}".contains("apache/cassandra")
}

/**
 * Are we running on ci-cassandra.apache.org ?
 **/
def isCanonical() {
  return "${JENKINS_URL}".contains("ci-cassandra.apache.org")
}

def isStageIncluded() {
    return true
}

/**
 * Executes `${build_script} ${jdk}` for each arch, and jdk.
 *
 * Stashes the jarfiles for `package-artifacts.sh`
 * Copies build artifacts and logfiles to nightlies
 * Cleans the agent (docker prune) afterwards
 * Stops the pipeline on any failure
 **/
def buildJob(build_script, toCopy) {
  if (! isStageIncluded()) {
    echo "Skipping ${STAGE_NAME}"
    return;
  }
  //def archs = ['cassandra', 'cassandra-arm64'] // uncomment when ready for arm64 testing
  def archs = ['cassandra']
  def jdks = "${javaVersionsSupported}".split(/,/, -1)
  def builds_per_arch = [:]
  for (a in archs) {
    def arch = a
    builds_per_arch[arch] = {
      def builds_per_jdk = [:]
      for (j in jdks) {
        def jdk = j
        builds_per_jdk["${STAGE_NAME} jdk:${jdk}"] = { _buildAxis(build_script, toCopy, arch, jdk) }
      }
      parallel(builds_per_jdk)
    }
  }
  parallel(builds_per_arch)
}

/**
 * Executes `${build_script} ${jdk}` for stated arch, and jdk.
 **/
def _buildAxis(build_script, toCopy, arch, jdk) {
  node(arch) {
    branchName: "${STAGE_NAME} ${build_script} ${jdk} ${NODE_NAME}"
    checkout scm
    //tool type: 'jdk', name: "jdk_${jdk}_latest"
    def statusCode = 0, attempt = 1
    retry(2) {
      if (attempt > 1) { sleep(60 * attempt) }
      def logfile = "${JOB_NAME}_${BUILD_NUMBER}_${STAGE_NAME}_jdk${jdk}_${arch}_attempt_${attempt}.log"
      sh "mkdir -p build"
      def build_dir = sh( returnStdout: true, script:"mktemp -d ${WORKSPACE}/build/build_docker_run.XXXXXXXXXX" ).trim()
      def build_dir_rel = build_dir - "${WORKSPACE}/"
      try {
        if ("jar" != STAGE_NAME) {
          dir("${build_dir}") {
            unstash name: "${arch}_${jdk}"
          }
        }
        echo "Executing ${STAGE_NAME} `build_dir=${build_dir} ${build_script} ${jdk} 2>&1 | tee ${logfile}` on ${NODE_NAME}"
        statusCode = sh returnStatus:true, script:"build_dir=\"${build_dir}\" ${build_script} ${jdk} 2>&1 | tee ${build_dir}/${logfile}"

        if ("jar" == STAGE_NAME) {
          dir("${build_dir}") {
            // only stash the project built files. all dependency libraries are restored from the local maven repo using `ant resolver-dist-lib`
            stash name: "${arch}_${jdk}"//, includes: "*.jar,classes/**,test/classes/**,tools/**"
          }
        }
      } finally {
        attempt = attempt + 1
        sh "xz -f ${build_dir}/*_attempt_*.log"
        dir("${build_dir}") {
            archiveArtifacts artifacts: "**/*_attempt_*.log.xz", fingerprint: true
            copyToNightlies("**/*_attempt_*.log.xz", "${STAGE_NAME}/jdk${jdk}/${arch}/")
            if (0 == statusCode) {
                copyToNightlies("${toCopy}", "${STAGE_NAME}/jdk${jdk}/${arch}/")
            }
        }
        sh "rm -rf \"${build_dir}\""
        cleanAgent(build_script)
        if (0 != statusCode) {
          currentBuild.result = 'FAILURE'
          error("FAILED ${STAGE_NAME}'${build_script} ${jdk}' on ${NODE_NAME}")
        } else {
          echo "Completed ${STAGE_NAME} '${build_script} ${jdk}' on ${NODE_NAME}"
        }
      }
    }
  }
}

/**
 * Saves JUnit results, fails if no reports are found
 * Copies (single-file unified) junit results and logfiles to nightlies
 * Cleans the agent (docker prune) afterwards
 * Stops the pipeline on any failure
 **/
def testJob(test_script, test_type, splits=1) {
  // we don't actually need the test_script and test_type, but they are useful explicit for readability and intuitive feedback in the declarative section.
  assert STAGE_NAME.equals(test_type) : "Stage's name expected to match test_type (" + STAGE_NAME + " != " + test_type + ")"
  assert ".build/docker/run-tests.sh".equals(test_script) : "testJob is hardcoded to '.build/docker/run-tests.sh', found " + test_script

  if (! isStageIncluded()) {
    echo "Skipping ${STAGE_NAME}"
    return;
  }

  // XXX – the following matrix over arrays can be better done with multi-arrays and recursion

  def archs = ['cassandra']
  def jdks = STAGE_NAME.contains("dtest-upgrade") || "simulator-dtest".equals(STAGE_NAME) ? ["${javaVersionDefault}"] : "${javaVersionsSupported}".split(/,/, -1)
  def pythons = "cqlshX".equals(STAGE_NAME) ? ['3.7', '3.8', '3.11'] : ['3.7']
  def cythons = "cqlshX".equals(STAGE_NAME) ? ['no', 'yes'] : ['no']

  def tests_per_arch = [:]
  for (a in archs) {
    def arch = a
    tests_per_arch[arch] = {
      def tests_per_jdk = [:]
      for (j in jdks) {
        def jdk = j
        tests_per_jdk[jdk] = {
          def tests_per_python = [:]
          for (p in pythons) {
            def python = p
            tests_per_python[python] = {
              def tests_per_cython = [:]
              for (c in cythons) {
                def cython = c
                tests_per_cython[cython] = {
                  def tests_per_split = [:]
                  for (int s = 1; s <= splits; s++) {
                    def split = s
                    tests_per_split["${test_type} jdk:${jdk} ${split}/${splits}"] = { _testAxis(test_script, test_type, arch, jdk, python, cython, "${split}/${splits}") }
                  }
                  parallel(tests_per_split)
                }
              }
              parallel(tests_per_cython)
            }
          }
          parallel(tests_per_python)
        }
      }
      parallel(tests_per_jdk)
    }
  }
  parallel(tests_per_arch)
}

/**
 * Executes `.build/test-docker.sh ${testDockerImage} ${test_type} ${split}` for the stated arch, jdk, python, cython, and split.
 **/
def _testAxis(test_script, test_type, arch, jdk, python, cython, split) {
  echo "Spawning ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python${python} cython=${cython}"
  node(arch) {
    branchName: "${STAGE_NAME} ${test_script} ${test_type} ${split} ${jdk} ${NODE_NAME}"
    echo "Starting ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python${python} cython=${cython} on ${NODE_NAME}"
    checkout scm
    sh "mkdir -p build"
    def build_dir = sh( returnStdout: true, script:"mktemp -d ${WORKSPACE}/build/build_docker_run.XXXXXXXXXX" ).trim()
    def build_dir_rel = build_dir - "${WORKSPACE}/"

    def cassandra_dtest_dir = "${build_dir}/cassandra-dtest"
    if (STAGE_NAME.startsWith("dtest")) {
        def dtestRepo = "https://github.com/apache/cassandra-dtest"
        def dtestBranch =  "trunk"
        sh "until git clone --quiet --depth 1 -b ${dtestBranch} ${dtestRepo} \"${cassandra_dtest_dir}\" ; do echo \"git cloning cassandra-dtest failed… trying again… \" ; done"
    }

    //tool type: 'jdk', name: "jdk_${jdk}_latest"
    def statusCode = 0, attempt = 1
    retry(2) {
      if (attempt > 1) { sleep(60 * attempt) }
      def logfile = "${JOB_NAME}_${BUILD_NUMBER}_${test_type}_jdk${jdk}_python_${python}_${cython}_${arch}_attempt_${attempt}.log"
      try {
        dir("${build_dir}") {
          unstash name: "${arch}_${jdk}"
        }
        echo "Executing ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk} 2>&1 | tee ${build_dir}/${logfile}` on ${NODE_NAME} with jdk=${jdk} python=${python} cython=${cython}"
        statusCode = sh returnStatus:true, script:"python_version=\"${python}\" cython=\"${cython}\" build_dir=\"${build_dir}\" cassandra_dtest_dir=\"${cassandra_dtest_dir}\" ${test_script} ${test_type} ${split} ${jdk} 2>&1 | tee ${build_dir}/${logfile}"
      } finally {
        dir("${build_dir_rel}") {
            if (0 == statusCode) {
                junit testResults: "test/output/**/TEST*.xml,test/output/cqlshlib.xml,test/output/nosetests.xml", testDataPublishers: [[$class: 'StabilityTestDataPublisher']]
                sh "xz -f test/output/**/TEST*.xml || true ; xz -f test/output/cqlshlib.xml test/output/nosetests.xml || true"
            }
            archiveArtifacts artifacts: "**/*_attempt_*.log.xz,test/logs/**,test/output/**/TEST*.xml.xz,test/output/cqlshlib.xml.xz,test/output/nosetests.xml.xz", fingerprint: true
            copyToNightlies("*_attempt_*.log.xz,test/logs/**", "${test_type}/${arch}/jdk${jdk}/python${python}/cython_${cython}/" + "split_${split}".replace("/", "_"))
        }
        sh "rm -rf \"${build_dir}\""
        cleanAgent(test_script)
        if (0 != statusCode) {
          currentBuild.result = 'FAILURE'
          error("FAILED ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python=${python} cython=${cython} on ${NODE_NAME}")
        } else {
          echo "Completed ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python=${python} cython=${cython} on ${NODE_NAME}"
        }
      }
    }

    if (currentBuild.result != 'SUCCESS') unstable("${STAGE_NAME} failures (arch=${arch} jdk=${jdk} python=${python} cython=${cython} on ${NODE_NAME})")
    if (currentBuild.result == 'ABORTED' && currentBuild.result != 'FAILURE') currentBuild.result='ABORTED'
    if (currentBuild.result == 'FAILURE') currentBuild.result='FAILURE'
  }
}

def copyToNightlies(sourceFiles, remoteDirectory='') {
  if (isCanonical()) {
    def remotePath = remoteDirectory.startsWith("cassandra/") ? "${remoteDirectory}" : "cassandra/${JOB_NAME}/${BUILD_NUMBER}/${remoteDirectory}"
    def attempt = 1
    retry(9) {
      if (attempt > 1) { sleep(60 * attempt) }
      sshPublisher(
        continueOnError: true, failOnError: false,
        publishers: [
          sshPublisherDesc(
          configName: "Nightlies",
          transfers: [ sshTransfer( sourceFiles: sourceFiles, remoteDirectory: remotePath) ]
          )
        ])
    }
    echo "archived to https://nightlies.apache.org/${remotePath}"
  }
}

def cleanAgent(job_name) {
  if (isCanonical()) {
    def maxJobHours = 12
    echo "Cleaning project, processes, docker for '${job_name}' on ${NODE_NAME}…" ;
    sh """
        git clean -qxdff -e build/test/jmh-result.json || true;
        if pgrep -xa docker || pgrep -af "build/docker" || pgrep -af "cassandra-builds/build-scripts" ; then docker system prune --all --force --filter "until=${maxJobHours}h" || true ; else  docker system prune --force --volumes || true ;  fi;
      """
  }
}

//  CASSANDRA-18130
def saveAgentReport() {
  if (isCanonical()) {
    //
    // echo "Updating disk usage report…";
    // sh """
    //     ( echo "----" ;
    //     echo \$(date) ;
    //     echo "${JOB_NAME} ${BUILD_NUMBER} ${STAGE_NAME}" ;
    //     du -xm / 2>/dev/null | sort -rn | head -n 30 ;
    //     df -h ) | tee -a \$(date +"%Y%m%d%H%M")-disk-usage-stats.txt
    //   """
    //   copyToNightlies("*-disk-usage-stats.txt", "cassandra/agents/${NODE_NAME}/disk-usage/")
    //   sh 'rm *-disk-usage-stats.txt'
  }
}

/////////////////////////////////////////
////// scripting support for summary ////
/////////////////////////////////////////

def generateUnifiedTestReport() {
  assert "Summary".equals(STAGE_NAME)
  node('cassandra') {
    checkout scm
    sh "mkdir -p build"
    copyArtifacts filter: 'test/output/**/*.xml.xz', fingerprintArtifacts: true, projectName: env.JOB_NAME, selector: specific(env.BUILD_NUMBER), target: "build/"
    sh 'xz -d build/test/output/**/*.xml.xz || true ; xz -d test/output/cqlshlib.xml test/output/nosetests.xml || true'
    sh ".build/docker/_docker_run.sh bullseye-build.docker generate-test-report.sh"
    dir('build/') {
      sh "xz -f TESTS-TestSuites.xml"
      archiveArtifacts artifacts: "TESTS-TestSuites.xml.xz,test/html/**/*", fingerprint: true
      copyToNightlies('TESTS-TestSuites.xml.xz')
    }
  }
}

def sendNotifications() {
  if (isPostCommit() && isCanonical()) {
    // the following is expected only to work on ci-cassandra.apache.org
    try {
      script {
        changes = formatChangeLogChanges(currentBuild.changeSets)
        echo "changes: ${changes}"
      }
      slackSend channel: '#cassandra-builds', message: ":apache: <${BUILD_URL}|${currentBuild.fullDisplayName}> completed: ${currentBuild.result}. <https://github.com/apache/cassandra/commit/${GIT_COMMIT}|${GIT_COMMIT}>\n${changes}"
      emailext to: 'builds@cassandra.apache.org', subject: "Build complete: ${currentBuild.fullDisplayName} [${currentBuild.result}] ${GIT_COMMIT}", presendScript: 'msg.removeHeader("In-Reply-To"); msg.removeHeader("References")', body: emailContent()
    } catch (Exception ex) {
      echo 'failed to send notifications  ' + ex.toString()
    }
  }
}

def formatChangeLogChanges(changeLogSets) {
  def result = ''
  for (int i = 0; i < changeLogSets.size(); i++) {
    def entries = changeLogSets[i].items
    for (int j = 0; j < entries.length; j++) {
      def entry = entries[j]
      result = result + "${entry.commitId} by ${entry.author} on ${new Date(entry.timestamp)}: ${entry.msg}\n"
    }
  }
  return result
}

def emailContent() {
  return '''
  -------------------------------------------------------------------------------
  Build ${ENV,var="JOB_NAME"} #${BUILD_NUMBER} ${BUILD_STATUS}
  URL: ${BUILD_URL}
  -------------------------------------------------------------------------------
  Changes:
  ${CHANGES}
  -------------------------------------------------------------------------------
  Failed Tests:
  ${FAILED_TESTS,maxTests=500,showMessage=false,showStack=false}
  -------------------------------------------------------------------------------
  For complete test report and logs see https://nightlies.apache.org/cassandra/${JOB_NAME}/${BUILD_NUMBER}/
  '''
}
