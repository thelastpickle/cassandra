// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//    https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.
//
//
// Jenkins declaration of how to build and test the current codebase.
//  Jenkins infrastructure related settings should be kept in
//    https://github.com/apache/cassandra-builds/blob/trunk/jenkins-dsl/cassandra_job_dsl_seed.groovy
//
// Validate/lint this file using the following command
// `curl -X POST  -F "jenkinsfile=<.jenkins/Jenkinsfile" https://ci-cassandra.apache.org/pipeline-model-converter/validate`

def jdksSupported = ["11", "17"] // Updating JDKs? Don't forget to update matrix axis (stages 'jar' and 'Tests'), they can't use variables :(
def archsSupported = ["amd64", "arm64"] // Updating Archs? Don't forget to update matrix axis (stages 'jar' and 'Tests'), they can't use variables :(
def jdkDefault = 11
def stageFailed = false

pipeline {
  agent none
  options {
    skipDefaultCheckout()
    // retry(3) // Do we need it?
    // githubProjectProperty('https://github.com/HadesArchitect/cassandra')
    // timestamps()
  }
  parameters {
    string(name: 'repository', defaultValue: 'https://github.com/HadesArchitect/cassandra', description: 'Cassandra Repository')
    string(name: 'branch', defaultValue: '*/aleks-cassius', description: 'Branch')
    choice(name: 'architecture', choices: archsSupported + "all", description: 'Pick architecture. The ARM64 is disabled by default at the moment.')
    choice(name: 'jdk', choices: jdksSupported + "all", description: 'Pick JDK versions.')
    booleanParam(name: 'stage_artifacts', defaultValue: false, description: 'Disable to exlude stage') // return default to true
    booleanParam(name: 'stage_lint', defaultValue: false) // return default to true
    booleanParam(name: 'stage_debian', defaultValue: false) // return default to true
    booleanParam(name: 'stage_redhat', defaultValue: false) // return default to true
    booleanParam(name: 'stage_fqltool-test', defaultValue: false) // return default to true
    booleanParam(name: 'stage_cqlsh-test', defaultValue: false) // return default to true
    booleanParam(name: 'stage_test', defaultValue: false) // return default to true
    booleanParam(name: 'stage_stress-test', defaultValue: false) // return default to true
    booleanParam(name: 'stage_test-compression', defaultValue: false) // return default to true
    booleanParam(name: 'stage_test-trie', defaultValue: false) // return default to true
  }
  environment {
    // javaVersionsSupported = jdksSupported.join(',')
    // javaVersionDefault = javaVersionDefault()
    javaVersionsSupported = jdksSupported.join(',')
    javaVersionDefault = "${jdkDefault}"
  }
  stages {
    // stage('init') {
    //   steps {
        // cleanWs(disableDeferredWipeout: true)
        // checkout changelog: false, scm: scmGit(branches: [[name: params.branch]], extensions: [cloneOption(depth: 1, noTags: true, reference: '', shallow: true)], userRemoteConfigs: [[url: params.repository]])
        // stash name: "repository", useDefaultExcludes: false
    //     script { currentBuild.result='SUCCESS' }
    //   }
    // }
    stage('jar') {
      matrix {
        axes {
          axis { 
            name 'arch'
            values 'amd64', 'arm64'
          }
          axis { 
            name 'jdk'
            values '11', '17'
          }
        }
        when {
          allOf {
            expression { isArchEnabled(env.arch) }
            expression { isJdkEnabled(env.jdk) }
          }
        }
        stages {
          stage('jar') {
            steps {
              _build("build-jars.sh")
            }
            post {
                failure { script { currentBuild.result='FAILURE' }}
            }
          }
        }
      }
    }
    stage('Tests') {
      failFast false
      matrix {
        axes {
            axis { 
              name 'arch'
              values 'amd64', 'arm64'
            }
            axis { 
              name 'jdk'
              values '11', '17'
            }
            // axis { 
            //   name 'python'
            //   values '3.7', '3.8', '3.11'
            // }
            axis { 
              name 'phase'
              values 'A', 'B'
            }
        }
        when {
          allOf {
            expression { isArchEnabled(env.arch) }
            expression { isJdkEnabled(env.jdk) }
            // expression { isStageEnabled(env.STAGE_NAME) } // In matrix-level `when` condition STAGE_NAME is "wrong" (MATRIX ARCH.. JDK...)
          }
        }
        stages {
          stage('artifacts') {
            when { 
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "A" == env.phase }
              }
            }
            steps {
                _build("build-artifacts.sh", "apache-cassandra-*.tar.gz,apache-cassandra-*.jar,apache-cassandra-*.pom")
            }
          }
          stage('lint') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "B" == env.phase }
              }
            }
            steps {
              _build("check-code.sh")
            }
          }
          stage('debian') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "A" == env.phase }
              }
            }
            steps {
              _build("build-debian.sh", "cassandra_*,cassandra-tools_*")
            }
          }
          stage('redhat') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "B" == env.phase }
              }
            }
            steps {
              _build("build-redhat.sh rpm", "*.rpm")
            }
          }
          stage('fqltool-test') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "A" == env.phase }
              }
            }
            steps {
              _test("fqltool-test")
            }
          }
        stage('test_1/10') {
            when {
              allOf {
                expression { isStageEnabled('test') }
                expression { "A" == env.phase }
              }
            }
            steps {
              _test("test", [current: 1, all: 40])
            }
          }
        stage('test_2/10') {
            when {
              allOf {
                expression { isStageEnabled('test') }
                expression { "B" == env.phase }
              }
            }
            steps {
              _test("test", [current: 2, all: 40])
            }
          }
        stage('test-compression_1/10') {
          when {
            allOf {
              expression { isStageEnabled('test-compression') }
              expression { "B" == env.phase }
            }
          }
          steps {
            _test("test-compression", [current: 1, all: 10])
          }
        }
        stage('test-compression_2/10') {
          when {
            allOf {
              expression { isStageEnabled('test-compression') }
              expression { "B" == env.phase }
            }
          }
          steps {
            _test("test-compression", [current: 2, all: 10])
          }
        }
        stage('stress-test') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "A" == env.phase }
              }
            }
            steps {
              _test("stress-test")
            }
          }
        stage('cqlsh-test') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "A" == env.phase }
              }
            }
            steps {
              _test("cqlsh-test")
            }
        }
        stage('test-trie') {
            when {
              allOf {
                expression { isStageEnabled(env.STAGE_NAME) }
                expression { "A" == env.phase }
              }
            }
            steps {
              _test('test-trie')
            }
          }
        }
      }
    }

    //         testJob("test-trie", 8)
    //         testJob("test-burn", 10)
    //         testJob("test-cdc", 10)
    //         testJob("long-test", 8)
    //         testJob("test-oa", 8)
    //         testJob("test-system-keyspace-directory", 8)
    //         _dtest("jvm-dtest", 8)
    //         testJob("jvm-dtest-upgrade", 8)
    //  
    // stage('Summary') {
    //   steps {
    //     // generateUnifiedTestReport()
    //     // FIXME â€“ post always
    //     // sendNotifications()
    //     script {
    //       if (stageFailed) {
    //         currentBuild.result='FAILURE'
    //         error("Build failed due to failed stages")
    //       }
    //     }
    //   }
    // }
  // }
//   post {
//     always {
//       cleanWs()
//     }
//   }
  }
}

///////////////////////////
//// scripting support ////
///////////////////////////

/**
 * Return the default JDK defined by build.xml
 **/
def javaVersionDefault() {
  sh (returnStdout: true, script: 'grep \'property\\s*name=\"java.default\"\' build.xml | sed -ne \'s/.*value=\"\\([^\"]*\\)\".*/\\1/p\'').trim()
}

/**
 * Return the supported JDKs defined by build.xml
 **/
def javaVersionsSupported() {
  sh (returnStdout: true, script: 'grep \'property\\s*name=\"java.supported\"\' build.xml | sed -ne \'s/.*value=\"\\([^\"]*\\)\".*/\\1/p\'').trim()
}

/**
 * Is this a post-commit build (or a pre-commit build)
 **/
def isPostCommit() {
  // any build of a branch found on github.com/apache/cassandra is considered a post-commit (post-merge) CI run
  return "${GIT_URL}".contains("apache/cassandra")
}

/**
 * Are we running on ci-cassandra.apache.org ?
 **/
def isCanonical() {
  return "${JENKINS_URL}".contains("ci-cassandra.apache.org")
}

def isStageEnabled(stage) {
  return params."stage_${stage}" || "jar" == stage
}

def isArchEnabled(arch) {
  return params.architecture == arch || "all" == params.architecture
}

def isJdkEnabled(jdk) {
  return params.jdk == jdk || "all" == params.jdk
}

// def _axis() {
//   return axis { 
//     name 'arch'
//     values 'amd64', 'arm64'
//   }
// }

/**
 * Renders build script into pipeline steps
 **/
def _build(build_script, toCopy="") {
    node(getNodeArch(arch)) {
        ws("workspace/${JOB_NAME}/${BUILD_NUMBER}/${STAGE_NAME}/${arch}/jdk-${jdk}/${env.phase}") {
            cleanWs(disableDeferredWipeout: true)
            fetchSource(STAGE_NAME, arch, jdk)

            build_script = ".build/docker/${build_script}"
            def logfile = "${JOB_NAME}_${BUILD_NUMBER}_${STAGE_NAME}_jdk${jdk}_${arch}.log"

            catchError(buildResult: null, message: 'Build task failed', stageResult: 'FAILURE') {
                // sh script:"#!/usr/bin/bash; set -o pipefail; build_dir='${WORKSPACE}/build' ${build_script} ${jdk} 2>&1 | tee ${logfile}"
                sh label: 'RUNNING BUILD TASK...', script: "#!/usr/bin/bash \nset -o pipefail; build_dir='${WORKSPACE}/build' ${build_script} ${jdk} 2>&1 | tee ${logfile}"
                if ("jar" == STAGE_NAME) { // only stash the project built files. all dependency libraries are restored from the local maven repo using `ant resolver-dist-lib`
                    stash name: "${arch}_${jdk}", useDefaultExcludes: false //, includes: '**/*.jar' //, includes: "*.jar,classes/**,test/classes/**,tools/**"
                }
                copyToNightlies("${toCopy}", "${STAGE_NAME}/jdk${jdk}/${arch}/")
            }
            sh "xz -f *.log"
            archiveArtifacts artifacts: "**/*.log.xz", fingerprint: true
            copyToNightlies("**/*.log.xz", "${STAGE_NAME}/jdk${jdk}/${arch}/")
            cleanAgent(build_script)
        }
    }
}

def _test(test_type, Map split = [current: 1, all: 1]) { //, arch, jdk, python, cython, split) {
  def python = "3.7"
  def cython = "no"
  node(getNodeArch(arch)) {
    ws("workspace/${JOB_NAME}/${BUILD_NUMBER}/${STAGE_NAME}/${arch}/jdk-${jdk}/${env.phase}") {
      cleanWs(disableDeferredWipeout: true)
      fetchSource(STAGE_NAME, arch, jdk)

      //def logfile = "${WORKSPACE}/build/${JOB_NAME}_${BUILD_NUMBER}_${test_type}_jdk${jdk}_python_${python}_${cython}_${arch}.log"

sh "mkdir -p build"
def build_dir = sh( returnStdout: true, script:"mktemp -d ${WORKSPACE}/build/build_docker_run.XXXXXXXXXX" ).trim()
def build_dir_rel = build_dir - "${WORKSPACE}/"

      catchError(buildResult: null, message: 'Tests failed', stageResult: 'FAILURE') {
          // sh label: "RUNNING TESTS...", script: "#!/usr/bin/bash \nset -o pipefail; python_version='${python}' cython='${cython}' build_dir='${WORKSPACE}/build' .build/docker/run-tests.sh ${test_type} '${split.current}/${split.all}' ${jdk} 2>&1 | tee ${logfile}"
          sh label: "RUNNING TESTS...", script: "#!/usr/bin/bash \nset -o pipefail; python_version='${python}' cython='${cython}' build_dir='${build_dir}' .build/docker/run-tests.sh ${test_type} '${split.current}/${split.all}' ${jdk} 2>&1"
          dir("${build_dir_rel}") {
            // junit testResults: "test/output/nosetests.xml", allowEmptyResults: true
            // junit testResults: "test/output/cqlshlib.xml", allowEmptyResults: true
            //sh "ls -la test/output/"
            junit testResults: "test/output/**/TEST*.xml"//, allowEmptyResults: true
            sh "xz -f test/output/**/TEST*.xml || true ; xz -f test/output/cqlshlib.xml test/output/nosetests.xml || true"
            // junit testResults: "test/output/**/TEST*.xml,test/output/cqlshlib.xml,test/output/nosetests.xml", testDataPublishers: [[$class: 'StabilityTestDataPublisher']]
            // junit testResults: "build/test/output/**/TEST*.xml,build/test/output/cqlshlib.xml,build/test/output/nosetests.xml"//, testDataPublishers: [[$class: 'StabilityTestDataPublisher']]
            // sh "xz -f build/test/output/**/TEST*.xml || true ; xz -f build/test/output/cqlshlib.xml build/test/output/nosetests.xml || true"
          }
      }
      //sh "xz -f *.log"
      // archiveArtifacts artifacts: "*.log.xz,build/**/*.log.xz,build/test/logs/**,build/test/output/**/TEST*.xml.xz,build/test/output/cqlshlib.xml.xz,build/test/output/nosetests.xml.xz", fingerprint: true
      // archiveArtifacts artifacts: "build/**/*.log.xz,build/test/logs/**,build/test/output/**/TEST*.xml.xz,build/test/output/cqlshlib.xml.xz,build/test/output/nosetests.xml.xz", fingerprint: true
      // copyToNightlies("*.log.xz,build/test/logs/**", "${test_type}/${arch}/jdk${jdk}/python${python}/cython_${cython}/" + "split_${split.current}_${split.all}".replace("/", "_"))
      
      cleanAgent(".build/docker/run-tests.sh")
    }
  }
}

def fetchSource(stage, arch, jdk) {
    if ("jar" == stage) {
        checkout changelog: false, scm: scmGit(branches: [[name: params.branch]], extensions: [cloneOption(depth: 1, noTags: true, reference: '', shallow: true)], userRemoteConfigs: [[url: params.repository]])
    } else {
        unstash name: "${arch}_${jdk}"
    }
}

/**
 * Saves JUnit results, fails if no reports are found
 * Copies (single-file unified) junit results and logfiles to nightlies
 * Cleans the agent (docker prune) afterwards
 * Stops the pipeline on any failure
 **/
def testJob(test_type, splits=1) {

  test_script = ".build/docker/run-tests.sh"

  // we don't actually need the test_script and test_type, but they are useful explicit for readability and intuitive feedback in the declarative section.
  assert STAGE_NAME.equals(test_type) : "Stage's name expected to match test_type (" + STAGE_NAME + " != " + test_type + ")"

  // XXX â€“ the following matrix over arrays can be better done with multi-arrays and recursion

  def archs = ['amd64']
  def jdks = STAGE_NAME.contains("dtest-upgrade") || "simulator-dtest".equals(STAGE_NAME) ? ["${javaVersionDefault}"] : "${javaVersionsSupported}".split(/,/, -1)
  // jdks ?
  def pythons = "cqlshX".equals(STAGE_NAME) ? ['3.7', '3.8', '3.11'] : ['3.7']
  // default python 3.7, for `cqlshX` stage it's 3.7, 3.8, 3.11
  def cythons = "cqlshX".equals(STAGE_NAME) ? ['no', 'yes'] : ['no']
  // default no cython, for `cqlshX` test both

  def tests = [:]
  archs.each { arch ->
      jdks.each { jdk ->
          pythons.each { python ->
              cythons.each { cython ->
                  for (int s = 1; s <= splits; s++) {
                    def split = s
                    tests["${test_type} $arch jdk:$jdk ${split}/${splits}"] = 
                      { _testAxis(test_script, test_type, arch, jdk, python, cython, "${split}/${splits}") }
                  }
                  // (1..splits).each { split ->
                  //     tests["${test_type} $arch jdk:$jdk ${split}/${splits}"] =
                  //         { _testAxis(test_script, test_type, arch, jdk, python, cython, "${split}/${splits}") }
                  // }
              }
          }
      }
  }
  
  return tests
}

/**
 * Backward compatibility to support ci-cassandra.a.o Renders node architecture by real architecture name
 **/
def getNodeArch(arch) {
  switch(arch) {
    case "amd64":
      return "cassandra"
    case "arm64":
      return "cassandra-arm64"
    default:
      error("Unsupported architecture '${arch}'")
  }
}

/**
 * Executes `.build/test-docker.sh ${testDockerImage} ${test_type} ${split}` for the stated arch, jdk, python, cython, and split.
 **/
def _testAxis(test_script, test_type, arch, jdk, python, cython, split) {
  echo "Spawning ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python${python} cython=${cython}"
  node(_getNodeArch(arch)) {
    branchName: "${STAGE_NAME} ${test_script} ${test_type} ${split} ${jdk} ${NODE_NAME}"
    echo "Starting ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python${python} cython=${cython} on ${NODE_NAME}"
    checkout scm
    sh "mkdir -p build"
    def build_dir = sh( returnStdout: true, script:"mktemp -d ${WORKSPACE}/build/build_docker_run.XXXXXXXXXX" ).trim()
    def build_dir_rel = build_dir - "${WORKSPACE}/"

    def cassandra_dtest_dir = "${build_dir}/cassandra-dtest"
    if (STAGE_NAME.startsWith("dtest")) {
        def dtestRepo = "https://github.com/apache/cassandra-dtest"
        def dtestBranch =  "trunk"
        sh "until git clone --quiet --depth 1 -b ${dtestBranch} ${dtestRepo} \"${cassandra_dtest_dir}\" ; do echo \"git cloning cassandra-dtest failedâ€¦ trying againâ€¦ \" ; done"
    }

    def statusCode = 0, attempt = 1
    retry(2) {
      if (attempt > 1) { sleep(60 * attempt) }
      def logfile = "${JOB_NAME}_${BUILD_NUMBER}_${test_type}_jdk${jdk}_python_${python}_${cython}_${arch}_attempt_${attempt}.log"
      try {
        dir("${build_dir}") {
          unstash name: "${arch}_${jdk}"
        }
        echo "Executing ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk} 2>&1 | tee ${build_dir}/${logfile}` on ${NODE_NAME} with jdk=${jdk} python=${python} cython=${cython}"
        statusCode = sh returnStatus:true, script:"python_version=\"${python}\" cython=\"${cython}\" build_dir=\"${build_dir}\" cassandra_dtest_dir=\"${cassandra_dtest_dir}\" ${test_script} ${test_type} ${split} ${jdk} 2>&1 | tee ${build_dir}/${logfile}"
      } finally {
        dir("${build_dir_rel}") {
            if (0 == statusCode) {
                junit testResults: "test/output/**/TEST*.xml,test/output/cqlshlib.xml,test/output/nosetests.xml", testDataPublishers: [[$class: 'StabilityTestDataPublisher']]
                sh "xz -f test/output/**/TEST*.xml || true ; xz -f test/output/cqlshlib.xml test/output/nosetests.xml || true"
            }
            archiveArtifacts artifacts: "**/*_attempt_*.log.xz,test/logs/**,test/output/**/TEST*.xml.xz,test/output/cqlshlib.xml.xz,test/output/nosetests.xml.xz", fingerprint: true
            copyToNightlies("*_attempt_*.log.xz,test/logs/**", "${test_type}/${arch}/jdk${jdk}/python${python}/cython_${cython}/" + "split_${split}".replace("/", "_"))
        }
        sh "rm -rf \"${build_dir}\""
        cleanAgent(test_script)
        if (0 != statusCode) {
          currentBuild.result = 'FAILURE'
          error("FAILED ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python=${python} cython=${cython} on ${NODE_NAME}")
        } else {
          echo "Completed ${STAGE_NAME} `${test_script} ${test_type} ${split} ${jdk}` with arch=${arch} jdk=${jdk} python=${python} cython=${cython} on ${NODE_NAME}"
        }
      }
    }

    if (currentBuild.result != 'SUCCESS') unstable("${STAGE_NAME} failures (arch=${arch} jdk=${jdk} python=${python} cython=${cython} on ${NODE_NAME})")
    if (currentBuild.result == 'ABORTED' && currentBuild.result != 'FAILURE') currentBuild.result='ABORTED'
    if (currentBuild.result == 'FAILURE') currentBuild.result='FAILURE'
  }
}

def copyToNightlies(sourceFiles, remoteDirectory='') {
    if (!isCanonical() || "" == sourceFiles) {
        return;
    }

    def remotePath = remoteDirectory.startsWith("cassandra/") ? "${remoteDirectory}" : "cassandra/${JOB_NAME}/${BUILD_NUMBER}/${remoteDirectory}"
    def attempt = 1
    retry(9) {
        if (attempt > 1) { sleep(60 * attempt) }
        sshPublisher(
        continueOnError: true, failOnError: false,
        publishers: [
            sshPublisherDesc(
            configName: "Nightlies",
            transfers: [ sshTransfer( sourceFiles: sourceFiles, remoteDirectory: remotePath) ]
            )
        ])
    }
    echo "archived to https://nightlies.apache.org/${remotePath}"
}

def cleanAgent(job_name) {
  if (isCanonical()) {
    def maxJobHours = 12
    echo "Cleaning project, processes, docker for '${job_name}' on ${NODE_NAME}â€¦" ;
    sh """
        git clean -qxdff -e build/test/jmh-result.json || true;
        if pgrep -xa docker || pgrep -af "build/docker" || pgrep -af "cassandra-builds/build-scripts" ; then docker system prune --all --force --filter "until=${maxJobHours}h" || true ; else  docker system prune --force --volumes || true ;  fi;
      """
  }
}

//  CASSANDRA-18130
def saveAgentReport() {
  if (isCanonical()) {
    //
    // echo "Updating disk usage reportâ€¦";
    // sh """
    //     ( echo "----" ;
    //     echo \$(date) ;
    //     echo "${JOB_NAME} ${BUILD_NUMBER} ${STAGE_NAME}" ;
    //     du -xm / 2>/dev/null | sort -rn | head -n 30 ;
    //     df -h ) | tee -a \$(date +"%Y%m%d%H%M")-disk-usage-stats.txt
    //   """
    //   copyToNightlies("*-disk-usage-stats.txt", "cassandra/agents/${NODE_NAME}/disk-usage/")
    //   sh 'rm *-disk-usage-stats.txt'
  }
}

/////////////////////////////////////////
////// scripting support for summary ////
/////////////////////////////////////////

def generateUnifiedTestReport() {
  assert "Summary".equals(STAGE_NAME)
  node(_('amd64')) {
    checkout scm
    sh "mkdir -p build"
    copyArtifacts filter: 'test/output/**/*.xml.xz', fingerprintArtifacts: true, projectName: env.JOB_NAME, selector: specific(env.BUILD_NUMBER), target: "build/"
    sh 'xz -d build/test/output/**/*.xml.xz || true ; xz -d test/output/cqlshlib.xml test/output/nosetests.xml || true'
    sh ".build/docker/_docker_run.sh bullseye-build.docker generate-test-report.sh"
    dir('build/') {
      sh "xz -f TESTS-TestSuites.xml"
      archiveArtifacts artifacts: "TESTS-TestSuites.xml.xz,test/html/**/*", fingerprint: true
      copyToNightlies('TESTS-TestSuites.xml.xz')
    }
  }
}

def sendNotifications() {
  if (isPostCommit() && isCanonical()) {
    // the following is expected only to work on ci-cassandra.apache.org
    try {
      script {
        changes = formatChangeLogChanges(currentBuild.changeSets)
        echo "changes: ${changes}"
      }
      slackSend channel: '#cassandra-builds', message: ":apache: <${BUILD_URL}|${currentBuild.fullDisplayName}> completed: ${currentBuild.result}. <https://github.com/apache/cassandra/commit/${GIT_COMMIT}|${GIT_COMMIT}>\n${changes}"
      emailext to: 'builds@cassandra.apache.org', subject: "Build complete: ${currentBuild.fullDisplayName} [${currentBuild.result}] ${GIT_COMMIT}", presendScript: 'msg.removeHeader("In-Reply-To"); msg.removeHeader("References")', body: emailContent()
    } catch (Exception ex) {
      echo 'failed to send notifications  ' + ex.toString()
    }
  }
}

def formatChangeLogChanges(changeLogSets) {
  def result = ''
  for (int i = 0; i < changeLogSets.size(); i++) {
    def entries = changeLogSets[i].items
    for (int j = 0; j < entries.length; j++) {
      def entry = entries[j]
      result = result + "${entry.commitId} by ${entry.author} on ${new Date(entry.timestamp)}: ${entry.msg}\n"
    }
  }
  return result
}

def emailContent() {
  return '''
  -------------------------------------------------------------------------------
  Build ${ENV,var="JOB_NAME"} #${BUILD_NUMBER} ${BUILD_STATUS}
  URL: ${BUILD_URL}
  -------------------------------------------------------------------------------
  Changes:
  ${CHANGES}
  -------------------------------------------------------------------------------
  Failed Tests:
  ${FAILED_TESTS,maxTests=500,showMessage=false,showStack=false}
  -------------------------------------------------------------------------------
  For complete test report and logs see https://nightlies.apache.org/cassandra/${JOB_NAME}/${BUILD_NUMBER}/
  '''
}
